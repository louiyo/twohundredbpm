{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from cost import *\n",
    "import math\n",
    "from gradients import *\n",
    "from preprocessing import *\n",
    "from cross_validation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 51,
=======
<<<<<<< HEAD
   "execution_count": 113,
=======
   "execution_count": 26,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'Data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'Data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
=======
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 114,
=======
   "execution_count": 99,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
   "metadata": {},
   "source": [
    "## Getting the best hyper-parameters through cross-validation"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 103,
=======
<<<<<<< HEAD
   "execution_count": 150,
=======
   "execution_count": 100,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================Beginning cross validation of model  1 ================\n",
      "mean for  0.0015   0.8286291936904475\n",
      "mean for  0.002   0.8235046841220273\n",
      "mean for  0.0018   0.8285791496516935\n",
      "mean for  0.0021   0.8207422531828009\n",
      "mean for  0.0022   0.8170890383537514\n",
      "mean for  0.0015   0.8125850748658819\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-63f784cf9b83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtest_x_jet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtX__test_cross_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     _, best_param = cross_validation(train_y_jet, train_x_jet, w_, degrees = [11,12,13],\n\u001b[0m\u001b[0;32m     19\u001b[0m                                         lambdas=[0.0015, 0.002, 0.0018, 0.0021, 0.0022])\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\MA1\\Machine Learning\\twohundredbpm\\Project_1\\cross_validation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(y, tX, w0, model, k_fold, display, degrees, lambdas, gammas, max_iters)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                     w, acc = compute_model(y, tX_poly, w0_, k, indices, gamma_,\n\u001b[0m\u001b[0;32m     91\u001b[0m                                            lambda_, max_iters, model)\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\MA1\\Machine Learning\\twohundredbpm\\Project_1\\cross_validation.py\u001b[0m in \u001b[0;36mcompute_model\u001b[1;34m(y, x, w0, k, indices, gamma_, lambda_, max_iters, model)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mtrain_inds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_inds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_inds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "%matplotlib inline\n",
    "\n",
    "# Copying the lists to avoid referencing the same object\n",
    "tX_cross_validation = tX.copy()\n",
    "tX__test_cross_validation = tX_test.copy()\n",
    "\n",
    "tX_cross_validation = preprocess(tX_cross_validation)\n",
    "tX__test_cross_validation = preprocess(tX__test_cross_validation)\n",
    "\n",
    "for idx in [0]:\n",
    "    \n",
    "    print(\"================Beginning cross validation of model \", idx+1, \"================\")\n",
    "    \n",
    "    train_x_jet = tX_cross_validation[idx]\n",
    "    train_y_jet = y[idx]\n",
    "    test_x_jet = tX__test_cross_validation[idx]\n",
    "    \n",
    "    _, best_param = cross_validation(train_y_jet, train_x_jet, w_, degrees = [11,12,13],\n",
    "                                        lambdas=[0.0015, 0.002, 0.0018, 0.0021, 0.0022])\n",
    "\n",
    "    print(\"for model \", idx+1, \" best parameters are :\")\n",
    "    print(\"degree : \", best_param[0], \" lambda : \", best_param[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the models"
=======
    "minimums = []\n",
    "for jet_num in range(len(ids)):\n",
    "    minimums.append(ids_test[jet_num].min())\n",
    "the_minimum = min(minimums)\n",
    "print(the_minimum)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 151,
=======
   "execution_count": 101,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_rename_after = tX.copy()\n",
    "tX_test_rename_after = tX_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 152,
=======
   "execution_count": 102,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tX_rename_after = remove_non_defined_columns(tX_rename_after)\n",
    "tX_test_rename_after = remove_non_defined_columns(tX_test_rename_after)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 138,
=======
   "execution_count": 103,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(tX_rename_after[1]))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 250,
=======
   "execution_count": 104,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "beginning model  1\n",
      "mean for  0.001009312   0.8441243882177497\n",
      "hello  0.001009312\n",
      "mean for  0.0011   0.8441043708025985\n",
      "for model  1  best parameters are :\n",
      "degree :  11  lambda :  0.001009312\n"
=======
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# initializing prediction arrays\n",
    "y_pred = []\n",
    "y_total = np.zeros(len(tX_test[0]) + len(tX_test[1]) + len(tX_test[2]) + len(tX_test[3]))\n",
    "\n",
    "#setting up parameters\n",
    "degrees = [11, 12, 13, 12]\n",
    "lambdas = [0.001009312, 0.001009312, 1.1212e-05, 0.0000696969]\n",
    "\n",
    "\n",
    "for idx in [0]: #range(len(tX_rename_after)):\n",
=======
    "print(np.isnan(tX_rename_after[1]))"
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training on model  1\n",
      "The accuracy of model 0 is equal to 0.8437740834526037\n",
      "Beginning training on model  2\n",
      "The accuracy of model 1 is equal to 0.8069354173114619\n",
      "Beginning training on model  3\n",
      "The accuracy of model 2 is equal to 0.8367176799857083\n",
      "Beginning training on model  4\n",
      "The accuracy of model 3 is equal to 0.8397852373217831\n"
     ]
    }
   ],
   "source": [
    "# initializing prediction arrays\n",
    "y_pred = []\n",
    "y_total = np.zeros(len(tX_test[0]) + len(tX_test[1]) + len(tX_test[2]) + len(tX_test[3]))\n",
    "\n",
<<<<<<< HEAD
    "#setting up parameters\n",
    "degrees = [11, 12, 13, 12]\n",
    "lambdas = [0.0018, 0.001009312, 1.1212e-05, 0.0000696969]\n",
    "\n",
    "\n",
    "tX = preprocess(tX)\n",
    "tX_test = preprocess(tX_test)\n",
    "\n",
    "\n",
    "for idx in range(len(tX)):\n",
    "    print(\"Beginning training on model \", idx+1)\n",
    "\n",
    "    # extracting the values of specific group :\n",
    "    train_x_jet = tX[idx]\n",
    "    train_y_jet = y[idx]\n",
    "    test_x_jet = tX_test[idx]\n",
    "    \n",
    "    # Polynomial feature expansion :\n",
    "    tX_train_poly = polynomial_expansion(train_x_jet, degrees[idx])\n",
    "    tX_test_poly = polynomial_expansion(test_x_jet, degrees[idx])\n",
=======
    "# Mauvaise itération - itérer sur chaque dataset spécifique au particules 0,1,2, et 3.\n",
    "# Puis compute le model pour les particules avec le PRI_jet_num spécifique.\n",
    "for idx in range(len(tX_rename_after)):\n",
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
    "    print(\"beginning model \", idx+1)\n",
    "    \n",
    "    # initializing the prediction vector :\n",
    "    y_pred_ = np.zeros(len(tX_rename_after[idx]))\n",
    "    \n",
    "\n",
    "    # extracting the values of group idx :\n",
    "    train_x_jet_ = tX_rename_after[idx]\n",
    "    train_y_jet_ = y[idx]\n",
    "    test_x_jet_ = tX_test_rename_after[idx]\n",
    "    \n",
    "\n",
    "    # Removing additional outliers :\n",
    "    train_selected_x_jet = replace_non_defined(train_x_jet_)\n",
    "    test_selected_x_jet = replace_non_defined(test_x_jet_)\n",
    "    \n",
    "    train_selected_x_jet = train_selected_x_jet[:, np.nanstd(train_selected_x_jet, axis = 0) != 0]\n",
    "    test_selected_x_jet = test_selected_x_jet[:, np.nanstd(test_selected_x_jet, axis = 0) != 0]\n",
    "    \n",
<<<<<<< HEAD
    "    \"\"\" i=0\n",
    "    means = np.mean(train_selected_x_jet, axis = 0)\n",
    "    for mean in means:\n",
    "        print(mean)\n",
    "        i += 1\n",
    "    print(i)\"\"\"\n",
    "        \n",
=======
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
    "    # standardize :\n",
    "    tX_train_std, _, _ = standardize(train_selected_x_jet)\n",
    "    tX_test_std, _, _ = standardize(test_selected_x_jet)\n",
    "    \n",
    "    # Polynomial feature expansion :\n",
<<<<<<< HEAD
    "    \"\"\"tX_train_poly = polynomial_expansion(tX_train_std, degrees[idx])\n",
    "    tX_test_poly = polynomial_expansion(tX_test_std, degrees[idx])\n",
    "\n",
    "    w_, loss_ = ridge_regression(train_y_jet_, tX_train_poly, lambdas[idx])\"\"\"\n",
    "    \n",
    "    _, best_param = cross_validation(train_y_jet_, tX_train_std, w_, degrees = [11],\n",
    "                     lambdas=[0.001009312, 0.0011])\n",
    "    \n",
    "    \n",
    "    print(\"for model \", idx+1, \" best parameters are :\")\n",
    "    print(\"degree : \", best_param[0], \" lambda : \", best_param[1])\n",
    "    \n",
    "    #accuracy_ = compute_accuracy(train_y_jet_, tX_train_poly, w_)\n",
    "    #print('The accuracy of model {} is equal to {}'.format(int(idx),accuracy_))\n",
=======
    "    tX_train_poly = polynomial_expansion(tX_train_std, degrees[idx])\n",
    "    tX_test_poly = polynomial_expansion(tX_test_std, degrees[idx])\n",
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
    "\n",
    "    w_, loss_ = ridge_regression(train_y_jet, tX_train_poly, lambdas[idx])\n",
    "    \n",
    "    accuracy_ = compute_accuracy(train_y_jet, tX_train_poly, w_)\n",
    "    print('The accuracy of model {} is equal to {}'.format(int(idx),accuracy_))\n",
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
    "\n",
    "    # Computing test accuracy : (To be changed -> à mettre dans une nouvelle boucle)\n",
    "                                                \n",
    "    y_pred_jet = predict_labels(w_, tX_test_poly)\n",
    "    \n",
    "    y_pred.append(y_pred_jet)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsorting the data"
=======
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 165,
=======
   "execution_count": 97,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[-1. -1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1.\n",
      "  1. -1. -1. -1.  1. -1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1.  1.\n",
      " -1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1.]\n"
=======
      "[-0.13037023]\n",
      "(22164, 1)\n"
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "print(y_total[40:100])"
=======
    "print(w_[4])\n",
    "print(train_y_jet_.shape)"
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
=======
<<<<<<< HEAD
   "execution_count": 166,
=======
   "execution_count": 106,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568238\n",
      "568238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nà faire : faire correspondre les résultats de prédictions correspondant à \\nchaque type de particule aux index correspondants dans le y_total de taille 250k\\n-> peut-être en déduisant la valeur du id zéro avec la valeur de ids[jet_num][j]\\n'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 166,
=======
     "execution_count": 106,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
   "source": [
    "%%capture\n",
    "y_total = np.zeros(len(np.hstack(ids_test)))\n",
    "\n",
    "min_id_test = min(np.hstack(ids_test))\n",
    "\n",
    "ids_total = np.arange(len(y_total))\n",
    "ids_total += the_minimum\n",
    "\n",
    "for jet_num in range(len(y)):\n",
    "    for j in range(len(y_pred[jet_num])):\n",
<<<<<<< HEAD
    "        y_total[ids_test[jet_num][j] - min_id_test] = y_pred[jet_num][j]\n",
    "\n",
=======
    "        y_total[ids_test[jet_num][j] - the_minimum] = y_pred[jet_num][j]\n",
    "        \n",
    "\"\"\"\n",
    "à faire : faire correspondre les résultats de prédictions correspondant à \n",
    "chaque type de particule aux index correspondants dans le y_total de taille 250k\n",
    "-> peut-être en déduisant la valeur du id zéro avec la valeur de ids[jet_num][j]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 167,
=======
   "execution_count": 107,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       ...,\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 167,
=======
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       ...,\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 107,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
    "y_total.reshape(-1, 1)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
=======
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 168,
=======
   "execution_count": 108,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
   "metadata": {},
   "source": [
    "## Generate output"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 106,
=======
<<<<<<< HEAD
   "execution_count": 169,
=======
   "execution_count": 109,
>>>>>>> 437ff29b28ed66f213a83f1771fa4c37081d21fc
>>>>>>> e175c1a878488cffd34ec3e9d3dfd2e9e4e830d6
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'Data/doto.csv'\n",
    "create_csv_submission(ids_total, y_total, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
