def least_squares_GD(y, tx, initial_w, max_iters, gamma):
    # Linear regression using gradient descent
    return w, loss
  
  
def least_squares_SGD(y, tx, initial w, max iters, gamma):
    # Linear regression using stochastic gradient descent
    return w, loss
    

def least_squares(y, tx):
    # Least squares regression using normal equations
    return w, loss
    
    
def ridge_regression(y, tx, lambda ):
    # Ridge regression using normal equations
    return w, loss
    
    
def logistic_regression(y, tx, initial w, max iters, gamma):
    # Logistic regression using gradient descent or SGD
    return w, loss
    
    
def reg_logistic_regression(y, tx, lambda , initial w, max iters, gamma):
    # Regularized logistic regression using gradient descent or SGD
    return w, loss
